---
title: "Monte Carlo Localization"
excerpt: "<span style="color:gray"><i>Apr. 2021 ~ Dec. 2021 @ Robot Intelligence Team</i></span><br> <b>For refactoring and enhancing the performance of the 2D LiDAR-based localizer.</b>"
collection: portfolio
---
<!-- <br/><img src='/images/500x300.png'> -->

> Info.  
  _Apr. 2021 ~ Dec. 2021 at Robot Intelligence Team with 3 members._

### Goal & Need

The objective of this project was to perform a comprehensive and in-depth refactoring of the existing Monte Carlo Localizer module. This was done by adhering to fundamental theory, focusing on verifying the basics, and further incorporating advancements in related algorithms, all while minimizing impromptu heuristics that had not been looked into deeply through demonstrations.

### Approaches & Insights

* Monte Carlo Localization Fundamentals  
  Monte Carlo Localization (MCL) is an advanced algorithm based on the Bayesian filter and the particle filter. Its primary purpose is to probabilistically estimate a robot's pose within a predefined map. MCL consists of three main steps: prediction, which utilizes a motion model; measurement, which involves an observation model; and resampling. In our specific application, we use a motion model based on the wheel odometry of a non-holonomic mobile robot, and we gather sensor observations from point scans obtained through a 2D LiDAR. 

* Motion Model  
  This model with regards to robot's kinematics serves as state transition model, represented as the posterior $p(x_t | u_t, x_{t-1})$ according to motion control $u_t$.
  The state variable $x$ represents the robot's pose, defined as {x, y, theta}, which includes position and orientation based on the kinematics of a 2D mobile robot. The wheel odometry model predicts how the pose changes ($\Delta x, \Delta y, \Delta \theta$) in response to wheel movements.

  > We utilized translation data from the odometer driver and orientation information from the IMU driver. Although the information is received periodically through a ROS2 node, there are occasional irregularities in the time interval. Applying defensive code for this when calculating the relative pose is a critical concern for several modules.

  When representing the relative pose due to motion, as explained in probabilistic robotics <sup>[1]</sup>, we decomposed $u_t$ into three motion parameters and applied noise to each of these parameters. 4 noise parameters related to translation and rotation are used to determine the variance of the error distribution.

  > In various real experiments conducted in specific environments, such as uphill terrain, I've noticed the significant influence of these noise parameters on the robot's localization performance. Occasionally, these physical conditions introduce additional noise into odometry, which deviates from typical scenarios. Variations in the physical state and the reliability of driver-provided values can also lead to differences, even among robots of the same type. Furthermore, alterations in robot hardware can cause increased odometry noise due to mechanical characteristics. Hence, it is crucial to validate the core performance of odometry and engage in targeted parameter tuning tailored to the specific robot in question.

  > **Odometry performance profiling**  
  We recognized the importance of conducting detailed performance profiling to evaluate the reliability of data obtained from odometry. As a result, we carried out experiments to compare the pose predictions from odometry with ground truth data obtained through motion capture. This approach involved analyzing the paths generated by motion capture and odometry when the robot returned to the same location after undergoing complex motion in a confined space. The results demonstrated that odometry performance closely matched ground truth data, thus establishing a solid foundation for having confidence in the fundamental performance of wheel odometry under normal conditions when addressing localization issues in the future.

* Observation Model

  _Concept and implementation_

  This model plays a important role in estimating the likelihood of different robot poses given sensor measurements. The model defines the sensor model, including details about sensor characteristics, such as noise, range, and field of view. It represents how well the predicted sensor readings (based on the particle's pose) match the actual sensor measurements. The model can be represented as the conditional probability $p(z_t | x_t, m)$ of observing the actual sensor measurements $z_t$ given the particle's pose $x_t$ in the map $m$. The probability is ideally the product of the individual measurement likelihoods, $\prod_{k=1}^K p(z_t^k | x_t, m)$.

  For each particle's pose, the expected sensor readings are calculated to determine what sensor data would be expected to receive if the robot were at that pose. Then, the particles are evaluated by comparing with the actual sensor measurements as the ground truth. The likelihood function is needed to quantify the similarity between them. We modeled the function based on our LiDAR's characteristics modifying the probability distributions proposed in the book <sup>[1]</sup>. It gives the probability of observing the actual measurements given a particle's pose. Further, it is also used in the resampling step to update particle weights and estimate the robot's pose accurately in real time. I found that a well-defined and accurate observation model is critical for the success of MCL in robot localization tasks.

  > **LiDAR performance profiling**
    T.B.A

  > **Beam Model Test**
    T.B.A

  > an accurate model may require state variables that we might not know
(such as the surface material)

* Resampling

  _Concept and implementation_
  **Resampling Step**:
  In the resampling step of MCL, you'll use the likelihood computed in the previous step to assign probabilities to each particle. Particles with poses that generate sensor readings that closely match the actual measurements will have higher probabilities of being selected during resampling.

  **Normalization**:
  After assigning probabilities to particles, it's essential to normalize them so that they sum to 1. This step ensures that the particle weights represent valid probability values.

  In the resampling process, it is essential to dynamically adjust the shape of the particle distribution or the number of particles at each step while accurately reflecting the uncertainty. However, this was not the case in the previous approach. To address this, we implemented the proposed KLD resampling as an Adaptive Particle Filter <sup>[3]</sup>. When observations are insufficient, we aimed for increased variance and a higher number of particles. Conversely, when observations are abundant, reducing uncertainty, we desired a narrower particle distribution with fewer particles for efficient computation.

  (KLD resampling takes a more adaptive and data-driven approach. Instead of using a fixed number of particles, it adjusts the number of particles dynamically based on the information content of the observations.)

  > **Particles exhibiting a linear distribution**
  Strangely, the particles appear to have non-uniform, linear distributions in the space rather than the typical circular patterns. To address this issue, we attempted approach A and resolved it through method B.

### Outcome

By testing in various environments and exploring artificial edge cases of sensor noise, we were able to confirm the performance advantage compared to the previous version. Through this process, we successfully applied the refactored outcome, achieving our goal of faithfully implementing the fundamentals of MCL while also resolving and validating the issues present in the previous version.

### References

[1] Probabilistic Robotics [[pdf]](https://docs.ufpr.br/~danielsantos/ProbabilisticRobotics.pdf)
[2] Particle Filter [[pdf]](https://people.eecs.berkeley.edu/~pabbeel/cs287-fa11/slides/particle-filters++_v2.pdf)
[3] KLD Sampling: Adaptive Particle Filter [[pdf]](https://proceedings.neurips.cc/paper/2001/file/c5b2cebf15b205503560c4e8e6d1ea78-Paper.pdf)
[4] Robust MCL for mobile robots [[pdf]](https://www2.informatik.uni-freiburg.de/~burgard/postscripts/robustMonteCarlo.pdf)
[5] MCL with Mixture Proposal Distribution [[pdf]](https://robots.stanford.edu/papers/thrun.hybrid-mcl.pdf)

> Yes! I finally stepped into the research on autonomous mobile robots that I had been longing for. However, the process of acquiring the necessary knowledge in this field and embarking on independent research was by no means easy.
