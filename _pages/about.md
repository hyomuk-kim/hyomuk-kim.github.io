---
permalink: /
title: "Hyomuk Kim"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

Currently I am a staff software engineer at _Robot Center, [Samsung Research](https://research.samsung.com)_ working on mobile robot navigation.
Recently I am diving deep into visual SLAM for 3D localization, mapping, and robust navigation.
I also endeavored to implement an optimal neural network for brain-computer interface and speech synthesis engine at *Global AI Center*.

Previously as a hardware engineer for 5 years,
I have developed circuit systems of various TV models at Visual Display Division, _[Samsung Electronics](https://www.samsung.com)_,
and as a planner and a manager for a year,
performed a project on an user contents archive platform based on multi device interfaces, leading the 6-member team at _C-Lab_.

This website is devoted to help you understand my journey for research more well.  
Download _[Curriculum Vitae](https://hyomuk-kim.github.io/files/cv_hyomuk-kim.pdf)_

***

## Education
* B.Sc. in Electrical & Electronics Engineering, _[Chung-Ang University](https://www.cau.ac.kr)_  
  -- *Feb 2011*
* Cadet in the Army _[ROTC](https://www.armyofficer.mil.kr:460/)_ (Reserved Officer Training Corps) program 49<sup>th</sup>  
  -- *Mar 2009 ~ Feb 2011*

## Research Objectives
### General Objectives
Determine how robots can understand semantic contexts of surroundings, navigate safely and fluently
in/out-door environments for various tasks and augment their intelligence by learning continuously.

### Specific Objectives
* Determine how autonomous robots and vehicles perfectly understand and navigate 3D space in the specific environments with various static and dynamic objects (wall, glass, pillar, furniture, human, etc.), using raw sensory data like images or scans from just a couple of sensors (e.g. only stereo camera), in terms of the specific constraints for feasible applications or products.

* Organize the ways to factorize the elements of scenes from visual sensors like semantic objects or diverse features utilizing novel neural fields as well as traditional features which are used for tracking, and identify how to parameterize geometrical properties so as to acquire elaborate representations of 3D spaces enough to use them as a map for planning later. Furthermore, examine how to fuse multiple visual informations and additional sensory data with less geometrical constraints to fluently adapt for varying sensor configurations.

* Describe how robots improve their navigation ability by various types of learning, what novel learning schemes could be applied, for instance, by grafting neural radiance field, diffusion model or reinforcement learning in robot navigation, and how they expand their world (concretely map) including multi layered indoor and outdoor environments incrementally, while explaining why robotâ€™s navigation should be evolved by machine learning.

* Examine how robots adapt special environments, such as underwater, forests and even outer space for the realization of the impeccable navigation, and assess how well they navigate across different types of those environments seamlessly, utilizing the aforementioned features from the point of view of realizing the life-long navigation of versatile robots.
