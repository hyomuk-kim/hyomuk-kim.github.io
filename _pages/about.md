---
permalink: /
title: "Hyomuk Kim"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

Currently I am a staff engineer and a **roboticist** at _Robot Center_, _[Samsung Research](https://research.samsung.com)_ working on mobile robot navigation.
Recently I am diving deep into **visual SLAM** for 3D localization, mapping, and robust navigation.
I also endeavored to implement an optimal neural network for brain-computer interface and speech synthesis engine at _Global AI Center_.

Previously as a hardware engineer for 5 years,
I have developed circuit systems of various TV models at Visual Display Division, _[Samsung Electronics](https://www.samsung.com)_,
and, as a planner and a manager for a year,
performed a project on an user contents archive platform based on multi device interfaces, leading the 6-member team at _C-Lab_.

This website is devoted to help you understand my journey for research more well.  
Download _[curriculum vitae](https://hyomuk-kim.github.io/files/cv_hyomuk-kim.pdf)_

***

## Education
* B.Sc. in Electrical & Electronics Engineering, _[Chung-Ang University](https://www.cau.ac.kr)_  
  -- _Feb 2011_
* Cadet in the Army _[ROTC](https://www.armyofficer.mil.kr:460/)_ (Reserved Officer Training Corps) program 49<sup>th</sup>  
  -- _Mar 2009 ~ Feb 2011_

## Research Objectives
### General Objectives
Determine how robots can understand semantic contexts of surroundings, navigate safely and fluently
in/out-door environments for various tasks and augment their intelligence by learning continuously.

### Specific Objectives
* Determine how autonomous robots and vehicles perfectly understand and navigate 3D space in the specific environments with various static and dynamic objects (_wall, glass, pillar, furniture, human, etc._), using raw sensory data like images or scans from just a couple of sensors (_e.g. only stereo camera_), in terms of the specific constraints for feasible applications or products.

* Organize the ways to factorize the elements of scenes from visual sensors like semantic objects or diverse features utilizing novel neural fields as well as traditional features which are used for tracking, and identify how to parameterize geometrical properties so as to acquire elaborate representations of 3D spaces enough to use them as a map for planning later. Furthermore, examine how to fuse multiple visual informations and additional sensory data to fluently adapt for varying sensor configurations with less geometrical constraints.

* Describe how robots improve their navigation ability by various types of learning, what novel learning schemes could be applied, for instance, by grafting _neural radiance fields_, _diffusion model_ or _reinforcement learning_ within robot navigation, and how they expand not only their world (concretely _map_) including multi layered indoor and outdoor environments but also their overall semantic perception incrementally, while explaining why robotâ€™s navigation should be evolved by machine learning.

* Examine how robots adapt to special environments, such as _underwater, forests and even outer space_ for the realization of the impeccable navigation, and assess how well they navigate across different types of those environments seamlessly, utilizing the aforementioned features from the point of view of realizing the life-long navigation of versatile robots.
